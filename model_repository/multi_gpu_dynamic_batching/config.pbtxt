name: "multi_gpu_dynamic_batching"
backend: "python"
max_batch_size: 8
instance_group [
  {
    kind: KIND_GPU
    count: 2
    gpus: [0, 1]
  }
]
dynamic_batching {
  preferred_batch_size: [1, 2, 4, 8]
  # This scheduling delay tells Triton how long to wait for additional requests. helps batch larger group of requests
  max_queue_delay_microseconds: 10000
}
input [
  {
    name: "INPUT"
    data_type: TYPE_STRING
    dims: [1]
  }
]
output [
  {
    name: "OUTPUT"
    data_type: TYPE_STRING
    dims: [1]
  }
]

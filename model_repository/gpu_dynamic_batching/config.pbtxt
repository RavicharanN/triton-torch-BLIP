name: "gpu_dynamic_batching"
backend: "python"
max_batch_size: 16
instance_group [
  {
    kind: KIND_GPU
    count: 1
    gpus: [0]
  }
]
dynamic_batching {
  preferred_batch_size: [4, 8, 16]
  # This scheduling delay tells Triton how long to wait for additional requests. helps batch larger group of requests
  max_queue_delay_microseconds: 100000
}
input [
  {
    name: "INPUT"
    data_type: TYPE_STRING
    dims: [1]
  }
]
output [
  {
    name: "OUTPUT"
    data_type: TYPE_STRING
    dims: [1]
  }
]
